
name-server:              
             maps name to url with array-server and id of array on that machine
             uniqueness is guaranteed on a single name-server only
             (for now).  The url + id is already a unique name, this
             is just a short-hand for use in applications.  It's like
             a variable name in an application as opposed to a memory
             address.  
                                            
An NDTable object holds and manages the relationship between 
   a high-level, array-oriented view of a collection of data and the
   low-level access and interpretation of that data which can be used for compute. 

NDTables are composed of a number of other ndtables.  In other-words,
there is a mapping between the shape and attribute lay-out of this
table and several other ndtables.   An "unchunked" ndtable is either:        

      remote (named with respect to a name-server)
          computations will be pushed where possible to the node where this array lives
      generated via an expression graph
      dtyped and transformed byte-buffer
             * General abstract "storage"
             * RAM
             * Random IO (seekable, block-seeking or byte-seeking)
                      * spinning disk
                      * solid state disk
             * Sequential IO
                      * socket 
                      * usb
                      * RS-232
                      * line-in
                      * frame-grabber
                      * tv-tuner
                      * other byte-based measurement data-source
             * remote memory
                      * url + 
                          disk / file
                          process / pointer
                          shared memory segment
                       * this is used to map data actually needed on a machine with no ndtable wrapper
             - byte-buffers have affinity information providing latency and bandwidth that a compute scheduler can use
             - byte-buffers are either readonly, writeable, or appendable

Each byte-buffer has a corresponding dtype which describes how the "bytes" should be interpreted during compute / processing
     To the standard NumPy dtypes we add: 
        * bit-pattern dtypes (a bit-pattern reserved for a mask)
        * masked dtypes (a bit-mask added for every N elements where N is a multiple of some word-size like 32 or 64)
        * arbitrary precision floats
        * arbitrary precision complex numbers
        * big integers
        * level dtypes
        * pointer dtypes (what is stored in the memory of a dtype is a reference to the actual data)
                * vararray dtypes (these are "ragged" dtypes where the memory is actually stored elsewhere and managed separately)
                * varutf8 dtypes
                * varbytes dtypes
                * pointer to a dtype 
                * pointer to another dtype-mapped buffer (this allows C-style arrays to be understood) 
                * far-reference dtypes (url + (disk, file) or url + (process, pointer))
        * array dtypes which take an index-mapping function to map the 'i,j,k,...' element to the linear N'th element of the array
                * special-case for strided cases
                * special-case for C-contiguous
                * special-case for F-contiguous
                * array dtypes maintain their character when constructed so that a (2,) array of (2,3) array-dtypes continues to have a shape of (2,) where every element is a (2,3) array.
        * expression dtypes (including expressions with null storage --- i.e. generated data).  
        * derived fields in structured arrays...
        * cell dtypes
        * block-expression dtypes (these dtypes are similar to expression dtypes except they take N elements of the underlying storage and return M elements of the result).   Indexes?  Variable-length blocks (N and/or M varying)?  Streams?  
        * Notice that a "transformation function" is subsubmed by the block-expression dtypes. 

        * Notice that a traditional dynamically allocated C-array with separate memory buffers can be understood with a memory buffer dtype that is a pointer to pointer to fundamental with a pointer to pointer to dtype 

        * Notice also that a traditional NumPy array is contained entirely in the array-dtype

Domains: 

         Basically, things that will be used to index an ndtable or
         define it's chunking. 
         Arithmetic (basically tuples of slice objects) --- these can be interleaved with step
         Sparse (fancy-indexing really -- actual indexes that will be selected)
         Cartesian index (Tensor product of specific per-dimension indexes)

Dimensions:                
           An NDTable contains a mapping between domains and chunks or
           dimensions and chunks. 
           An NDTable can contain only one chunk (i.e. generated
           arrays, 

           An NDTable also contains a dimension mapping that creates
           the shape from the underlying ndtable chunks.  

           Have properties  of ordering and indexing.  Standard
           dimensions are "integer" based and implicit.  Sparse
           dimensions replace one or more attributes in another
           ndtable and one or more dimensions.   Dimensions can be
           named (sparse dimensions get a default name consisting of
           their attributes).  Sparse dimensions can be ordered or
           unordered (i.e. cate
           Dimensions can be *labeled* by something thaaps a
           hashable type to an integer: 
                      * by a dictionary
                      * 1-d, 2-attribute ndtable
                      * a 2-d ndtable
                      * a 1-d 2-attribute ndarray
                      * a 2-d ndarray  or an ndarray

           * An NDTable is indexed via slicing on "dimensions" and accessing attributes.
           Question:   Should accessing an attribute be the same as
           accessing dimensions:  Yes, we should treat the attribute
           list as the last dimension.   One reason: the idea of
           sparse dimensions could be applied to a any non-attribute
           based.   Attributes become just another labeled dimension. 
        
Chunking patterns:

         * Chunking by attributes -- a new chunk for a set of
         attributes
         * Chunking by domains -- a chunk is defined by a particular
         partition of the ND and attribute space
               * Special cases are chunking along a specific dimension
               or sub-set of dimensions (i.e. entire range in other
               dimensions)
         * Chunking based on a mapping of a subset of the dimensions
         to a dimensional space that matches the underlying ndtable.
              The idea here is to support something like Z-order
              chunking for at least a sub-set of the dimensions.   In
              the simplest case the underlying buffer would be 1-d
              (but it could have additional "dimensionality" with just
              the leading dimension being un-rolled into the other
              dimensions). 
        
         All of these chunking patterns are subsumed under the common
         chunking rule (assuming attributes are seen as a dimension): 
                  * Chunking divides up the ndtable along 1 or more dimensions of
                     a mapped index set.   The mapping is Z^n to Z^m
                     where n and m can be different. 

           e.g. : 
                * (i,j,k,...) -> (I,J,K,...)   

                then the partition is on blocks of (I,J,K,...)

         Partitions can be:

          * concatenative (almost) uniform (define the chunk_size (100,200,100) +
            overlap factor (50,20,20) or just 50 )
          * concatenative map-based:  start,end N-d coordinates in a hash-table
            pointing to N-d ndtables
          * axis-based:  chunk_size + overlap and an axis or set of axes
          * axis-map-based:  start, end n-d coordinates and a set of n
            axes in a hash-table pointing to (N-n)-d ndtables.
        
Random thoughts:

       * Chapel's "vectorize" primitives are interesting consisting of standard "zip" promotion and tensor product promotion:
            --- should consider returning a vectorize function with tensor promotion that takes the input arguments and returns appends newaxis arguments.

            Suppose you have N-input arguments all 1-dim  then the kth input argument has shape (1,)*(N-k-1) + arg.shape + (1,)*k  with k starting at 0 and going to N-1

            N = 2:   arg0 = (5,) and arg1 = (7,)

                   (1,5) and (7,1)

            N = 3:  arg0 = (5,) and arg1 = (6,) and arg2 = (7,)

                   (1,1,5) and (1,6,1) and (7,1,1)


Read:   http://chapel.cray.com/spec/spec-0.775.pdf

Chapel also has the notion of locales which are compute-and-memory nodes.  We will borrow this idea. 
